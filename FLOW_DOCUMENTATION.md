# DOCUMENTACI√ìN COMPLETA DEL FLUJO P2P - FASE 5

## üéØ Flujo Principal: Login ‚Üí B√∫squeda ‚Üí Transfer ‚Üí Index

### üìã Resumen del Flujo Completo

```
1. LOGIN/BOOTSTRAP    ‚Üí Establecer red P2P distribuida
2. INDEXACI√ìN        ‚Üí Catalogar archivos locales de cada nodo  
3. B√öSQUEDA          ‚Üí Encontrar archivos remotos con flooding
4. TRANSFERENCIA     ‚Üí Descargar archivo real v√≠a gRPC streaming
5. INDEXACI√ìN AUTO   ‚Üí Catalogar archivo descargado autom√°ticamente
6. DISPONIBILIDAD    ‚Üí Archivo disponible localmente para futuras b√∫squedas
```

---

## üîê PASO 1: LOGIN Y BOOTSTRAP DE LA RED

### Objetivo
Establecer la topolog√≠a de red P2P donde cada nodo conoce a los dem√°s nodos activos.

### Implementaci√≥n T√©cnica
```python
# Nodo C se conecta a la red existente (Nodos A y B)
POST http://nodo-a:50001/directory/login
{
    "address": "nodo-c:50003"
}

POST http://nodo-b:50002/directory/login  
{
    "address": "nodo-c:50003"
}
```

### Flujo Detallado
1. **Nodo C inicia** su servidor REST en puerto 50003
2. **Nodo C realiza login** hacia Nodos A y B conocidos
3. **Nodos A y B** agregan direcci√≥n de C a su Directory List
4. **Nodo C solicita Directory List** completo de la red
5. **Red P2P establecida** - todos los nodos se conocen entre s√≠

### Logs de Ejemplo
```
[10:30:15] üîó peer3 ‚Üí LOGIN ‚Üí peer1
[10:30:15]    üì° Enviando POST /directory/login desde 127.0.0.1:50003
[10:30:15]    üìù Payload: {"address": "127.0.0.1:50003"}
[10:30:15]    ‚úÖ Respuesta HTTP 200: Login exitoso
[10:30:16] üìã peer3 ‚Üí DIRECTORY LIST
[10:30:16]    ‚úÖ Directory List obtenido: 3 peers conocidos
[10:30:16]       - 127.0.0.1:50001
[10:30:16]       - 127.0.0.1:50002
[10:30:16]       - 127.0.0.1:50003
```

### Resultado
- **Red P2P distribuida** establecida
- **Cada nodo** conoce la direcci√≥n de todos los dem√°s
- **Base para comunicaci√≥n** posterior preparada

---

## üìÅ PASO 2: INDEXACI√ìN DE ARCHIVOS LOCALES

### Objetivo
Cada nodo cataloga sus archivos locales para responder a b√∫squedas futuras.

### Implementaci√≥n T√©cnica
```python
# Cada nodo indexa sus archivos locales
POST http://nodo-x:5000x/indexar
{}

# Respuesta t√≠pica
{
    "message": "Indexaci√≥n completada",
    "total": 5,
    "archivos_indexados": [
        {"filename": "video_especial.mp4", "size": 15728640, "path": "/files/video_especial.mp4"},
        {"filename": "documento.pdf", "size": 2048576, "path": "/files/documento.pdf"}
    ]
}
```

### Flujo Detallado
1. **Escaneo recursivo** del directorio configurado (`files_directory`)
2. **Extracci√≥n de metadatos** - nombre, tama√±o, ruta completa
3. **Almacenamiento en √≠ndice** en memoria (variable `_INDEX`)
4. **Inclusi√≥n de downloads** - archivos descargados previamente
5. **√çndice actualizado** y listo para b√∫squedas

### Logs de Ejemplo
```
[10:30:20] üìÅ peer1 ‚Üí INDEXAR ARCHIVOS
[10:30:20]    üì° Enviando POST /indexar desde 127.0.0.1:50001
[10:30:20]    ‚úÖ Indexaci√≥n completada: 8 archivos indexados
[10:30:21] üìÅ peer3 ‚Üí INDEXAR ARCHIVOS  
[10:30:21]    ‚úÖ Indexaci√≥n completada: 3 archivos indexados
```

### Resultado
- **Cat√°logo local** actualizado en cada nodo
- **Metadatos disponibles** para responder b√∫squedas
- **Base de datos distribuida** lista

---

## üîç PASO 3: B√öSQUEDA DISTRIBUIDA CON FLOODING

### Objetivo
Encontrar un archivo espec√≠fico en cualquier nodo de la red usando propagaci√≥n de mensajes.

### Implementaci√≥n T√©cnica
```python
# Nodo C busca archivo que no tiene localmente
GET http://nodo-c:50003/directory/search/simple/video_especial.mp4

# Proceso interno de flooding:
1. Buscar localmente en √≠ndice de C
2. Si no encontrado, propagar a nodos conocidos con TTL=3
3. Cada nodo busca localmente y propaga (TTL-1)
4. Evitar duplicados con QuerySet (max 5 queries)
5. Recolectar y retornar resultados
```

### Algoritmo de Flooding
```python
def flooding_search(filename, query_id, ttl=3, visited_nodes=set()):
    # 1. B√∫squeda local
    local_results = search_in_local_index(filename)
    
    if local_results:
        return local_results
    
    # 2. Propagaci√≥n a nodos vecinos
    if ttl > 0:
        for neighbor_node in get_directory_list():
            if neighbor_node not in visited_nodes:
                remote_results = propagate_search(
                    neighbor_node, filename, query_id, ttl-1, visited_nodes
                )
                all_results.extend(remote_results)
    
    return all_results
```

### Flujo Detallado
1. **Nodo C** recibe solicitud de b√∫squeda para `video_especial.mp4`
2. **B√∫squeda local** en √≠ndice de C - no encontrado
3. **Generaci√≥n de Query ID** √∫nico para evitar loops
4. **Propagaci√≥n** a Nodos A y B con TTL=3
5. **Nodo A** busca localmente - **ENCONTRADO**
6. **Nodo A** retorna resultado a C
7. **Nodo B** busca localmente - no encontrado, no propaga (TTL)
8. **Nodo C** recolecta resultados y responde al cliente

### Logs de Ejemplo
```
[10:30:25] üîç peer3 ‚Üí B√öSQUEDA DISTRIBUIDA: 'video_especial.mp4'
[10:30:25]    üì° Enviando GET /directory/search/simple/video_especial.mp4
[10:30:25]    üåä Iniciando flooding con TTL=3...
[10:30:26]    ‚úÖ B√∫squeda completada: 1 resultados encontrados
[10:30:26]       üìç Encontrado en 127.0.0.1:50001 (15728640 bytes)
```

### Resultado
- **Archivo localizado** en Nodo A (127.0.0.1:50001)
- **Metadatos obtenidos** - tama√±o, ubicaci√≥n exacta
- **Informaci√≥n de transferencia** disponible

---

## üì• PASO 4: TRANSFERENCIA REAL V√çA gRPC STREAMING

### Objetivo
Descargar el archivo real desde el nodo que lo contiene usando gRPC con streaming eficiente.

### Implementaci√≥n T√©cnica
```python
# Cliente gRPC en Nodo C
client = TransferClient("127.0.0.1:50003")
success = await client.download_file(
    target_node="127.0.0.1:50001",  # Nodo A (donde est√° el archivo)
    filename="video_especial.mp4",
    save_path="downloads/video_especial.mp4"
)
```

### Protocolo gRPC
```protobuf
service TransferService {
    rpc Download(FileRequest) returns (stream FileChunk);
}

message FileRequest {
    string filename = 1;
    string requesting_node = 2;
}

message FileChunk {
    string filename = 1;
    bytes data = 2;              // 64KB por chunk
    int32 chunk_number = 3;
    int64 total_size = 4;
    bool is_last_chunk = 5;
}
```

### Flujo Detallado
1. **Nodo C** establece conexi√≥n gRPC con Nodo A (puerto 51001)
2. **Solicitud Download** con nombre de archivo
3. **Nodo A** localiza archivo en su filesystem
4. **Streaming por chunks** - archivo dividido en bloques de 64KB
5. **Nodo C** recibe chunks secuencialmente
6. **Ensamblaje** de chunks en archivo completo
7. **Verificaci√≥n** de integridad y tama√±o
8. **Archivo guardado** en directorio de descargas

### Logs de Ejemplo
```
[10:30:30] üì• peer3 ‚Üí DESCARGA gRPC: 'video_especial.mp4' desde 127.0.0.1:50001
[10:30:30]    üîó Estableciendo conexi√≥n gRPC...
[10:30:30]    üì° Cliente: 127.0.0.1:50003, Servidor: 127.0.0.1:50001
[10:30:30]    üíæ Ruta de descarga: downloads/video_especial.mp4
[10:30:30]    üöÄ Iniciando transferencia con streaming...
[10:30:32]    ‚úÖ Transferencia exitosa!
[10:30:32]    üìä Archivo descargado: 15728640 bytes en 2.15s
[10:30:32]    üìÅ Indexaci√≥n autom√°tica iniciada...
```

### Ventajas del Streaming
- **Eficiencia de memoria** - no cargar archivo completo
- **Progreso en tiempo real** - chunks individuales
- **Tolerancia a interrupciones** - reanudar desde √∫ltimo chunk
- **Escalabilidad** - archivos de cualquier tama√±o

### Resultado
- **Archivo transferido** completamente a Nodo C
- **Integridad verificada** - tama√±o y contenido
- **Disponible localmente** en directorio de descargas

---

## üìã PASO 5: INDEXACI√ìN AUTOM√ÅTICA POST-TRANSFERENCIA

### Objetivo
Catalogar autom√°ticamente el archivo descargado para disponibilidad en b√∫squedas futuras.

### Implementaci√≥n T√©cnica
```python
# Ejecutado autom√°ticamente tras descarga exitosa
def indexar_archivo_descargado(file_path: str) -> bool:
    filename = os.path.basename(file_path)
    size = os.path.getsize(file_path)
    
    # Verificar duplicados
    for existing in _INDEX:
        if existing["path"] == file_path:
            return True  # Ya indexado
    
    # Agregar al √≠ndice
    _INDEX.append({
        "filename": filename,
        "path": file_path,
        "size": size,
    })
    
    return True
```

### Flujo Detallado
1. **Download exitoso** dispara evento de indexaci√≥n
2. **Extracci√≥n de metadatos** del archivo descargado
3. **Verificaci√≥n de duplicados** en √≠ndice actual
4. **Inserci√≥n en √≠ndice** local de Nodo C
5. **Archivo disponible** para b√∫squedas futuras desde C
6. **Confirmaci√≥n** de indexaci√≥n en logs

### Logs de Ejemplo
```
[10:30:32] üìã peer3 ‚Üí VERIFICAR INDEXACI√ìN POST-TRANSFER
[10:30:32]    üîç Verificando si 'video_especial.mp4' est√° indexado localmente...
[10:30:33]    ‚úÖ Archivo indexado correctamente:
[10:30:33]       üìÅ Nombre: video_especial.mp4
[10:30:33]       üìä Tama√±o: 15728640 bytes
[10:30:33]       üìç Ruta: downloads/video_especial.mp4
```

### Resultado
- **Archivo indexado** en cat√°logo local de Nodo C
- **Metadatos actualizados** - nombre, tama√±o, ruta
- **Disponible para compartir** con otros nodos

---

## üéØ PASO 6: VERIFICACI√ìN DE DISPONIBILIDAD LOCAL

### Objetivo
Confirmar que el archivo est√° ahora disponible localmente y puede ser encontrado en b√∫squedas.

### Implementaci√≥n T√©cnica
```python
# Nueva b√∫squeda del mismo archivo desde Nodo C
GET http://nodo-c:50003/directory/search/simple/video_especial.mp4

# Ahora deber√≠a encontrar el archivo LOCALMENTE
# Sin necesidad de flooding a otros nodos
```

### Flujo Detallado
1. **Nueva b√∫squeda** de `video_especial.mp4` desde Nodo C
2. **B√∫squeda local** en √≠ndice actualizado de C
3. **ENCONTRADO LOCALMENTE** - resultado inmediato
4. **Sin propagaci√≥n** necesaria a otros nodos
5. **Archivo disponible** para futuras transferencias
6. **Nodo C** ahora puede servir el archivo a otros nodos

### Logs de Ejemplo
```
[10:30:35] üéØ peer3 ‚Üí VERIFICACI√ìN DE DISPONIBILIDAD LOCAL
[10:30:35] üîç peer3 ‚Üí B√öSQUEDA DISTRIBUIDA: 'video_especial.mp4'
[10:30:35]    üì° Enviando GET /directory/search/simple/video_especial.mp4
[10:30:35]    ‚úÖ B√∫squeda completada: 2 resultados encontrados
[10:30:35]       üìç Encontrado en 127.0.0.1:50001 (15728640 bytes)  # Original
[10:30:35]       üìç Encontrado en 127.0.0.1:50003 (15728640 bytes)  # Nueva copia
```

### Resultado Final
- **Archivo replicado** exitosamente en la red
- **Disponibilidad aumentada** - ahora en 2 nodos
- **Tolerancia a fallos mejorada** - respaldo autom√°tico
- **Distribuci√≥n de carga** - m√∫ltiples fuentes de descarga

---

## üîÑ CONCURRENCIA EN EL SISTEMA

### ¬øC√≥mo se Logra la Concurrencia?

#### 1. **Servidor Dual: REST + gRPC**
```python
# Arquitectura de servidores concurrentes
async def main():
    # Servidor REST (FastAPI) - Puerto 50001
    rest_server = uvicorn.run(app, host="0.0.0.0", port=50001)
    
    # Servidor gRPC - Puerto 51001 (hilo separado)
    grpc_thread = threading.Thread(
        target=run_grpc_server,
        args=("0.0.0.0", 51001, node_address, files_dir),
        daemon=True
    )
    grpc_thread.start()
```

#### 2. **Operaciones As√≠ncronas**
```python
# M√∫ltiples operaciones simult√°neas sin bloqueo
async def handle_multiple_requests():
    tasks = []
    
    # 10 b√∫squedas simult√°neas
    for i in range(10):
        task = search_file(f"query_{i}")
        tasks.append(task)
    
    # Ejecutar todas en paralelo
    results = await asyncio.gather(*tasks)
    return results
```

#### 3. **HTTP Client Pool**
```python
# Pool de conexiones para comunicaci√≥n entre nodos
class AsyncHTTPClient:
    def __init__(self):
        self.session = aiohttp.ClientSession(
            connector=aiohttp.TCPConnector(limit=100),  # 100 conexiones concurrentes
            timeout=aiohttp.ClientTimeout(total=10)
        )
```

#### 4. **gRPC Streaming As√≠ncrono**
```python
# Streaming no bloquea otras operaciones
async def download_file_concurrent(node, filename):
    async with grpc.aio.insecure_channel(grpc_address) as channel:
        stub = TransferServiceStub(channel)
        
        # Stream as√≠ncrono - no bloquea el hilo principal
        async for chunk in stub.Download(request):
            process_chunk(chunk)  # Procesamiento incremental
```

### Beneficios de la Concurrencia
- **M√∫ltiples b√∫squedas** simult√°neas sin interferencia
- **Transferencias paralelas** de diferentes archivos
- **Indexaci√≥n no bloquea** otras operaciones
- **Escalabilidad horizontal** - m√°s nodos = m√°s concurrencia

---

## üõ°Ô∏è TOLERANCIA A FALLOS

### Mecanismos Implementados

#### 1. **Detecci√≥n de Nodos Ca√≠dos**
```python
# Health check autom√°tico
async def check_node_health(node_address):
    try:
        async with aiohttp.ClientSession(timeout=ClientTimeout(total=3)) as session:
            async with session.get(f"http://{node_address}/directory/dl/all") as response:
                return response.status == 200
    except:
        return False
```

#### 2. **Redundancia de Red**
- **M√∫ltiples rutas** - cada nodo conoce a todos los dem√°s
- **Sin punto √∫nico de fallo** - red descentralizada
- **Replicaci√≥n autom√°tica** - archivos distribuidos tras transferencia

#### 3. **Recuperaci√≥n de Fallos**
```python
# Reintentos autom√°ticos con backoff exponencial
async def resilient_request(url, max_retries=3):
    for attempt in range(max_retries):
        try:
            return await make_request(url)
        except Exception:
            wait_time = 2 ** attempt  # Backoff exponencial
            await asyncio.sleep(wait_time)
    
    raise Exception("Max retries exceeded")
```

#### 4. **Graceful Degradation**
- **B√∫squedas contin√∫an** aunque algunos nodos fallen
- **Transferencias alternativas** desde m√∫ltiples fuentes
- **Red se mantiene funcional** con 2/3 nodos activos

### Demostraci√≥n de Tolerancia
```python
# Simulaci√≥n de fallo de nodo
def simulate_node_failure():
    print("‚ö° SIMULANDO fallo de peer2...")
    # Nodo peer2 se desconecta temporalmente
    
    # Red contin√∫a funcionando
    search_result = search_from_peer1("video_especial.mp4")
    assert search_result.success  # ‚úÖ B√∫squeda exitosa
    
    # Recuperaci√≥n autom√°tica
    print("üîÑ SIMULANDO recuperaci√≥n de peer2...")
    # Nodo peer2 se reconecta
    
    network_health = check_all_nodes()
    assert network_health.all_active  # ‚úÖ Red completamente recuperada
```

---

## üìä M√âTRICAS Y VALIDACI√ìN

### Criterios de √âxito Cumplidos

#### ‚úÖ **Funcionalidad B√°sica**
- Login y bootstrap de red P2P
- Indexaci√≥n distribuida de archivos
- B√∫squeda con flooding y TTL
- Transferencia real de archivos (no solo metadatos)

#### ‚úÖ **Concurrencia**
- 20+ operaciones simult√°neas sin degradaci√≥n
- Tasa de √©xito > 85% en pruebas concurrentes
- Throughput > 10 operaciones/segundo

#### ‚úÖ **Tolerancia a Fallos**
- Red sobrevive ca√≠da de nodos individuales
- Recuperaci√≥n autom√°tica tras fallos
- Funcionalidad preservada con 2/3 nodos activos

#### ‚úÖ **Rendimiento**
- Tiempo de respuesta < 1 segundo promedio
- Transferencias eficientes con streaming
- Uso optimizado de recursos del sistema

### Validaci√≥n End-to-End
```
ENTRADA: Nodo C busca "video_especial.mp4" (no lo tiene)
SALIDA:  Nodo C tiene "video_especial.mp4" localmente disponible

PROCESO VALIDADO:
‚úÖ Login/Bootstrap ‚Üí Red P2P establecida
‚úÖ B√∫squeda distribuida ‚Üí Archivo encontrado en Nodo A  
‚úÖ Transferencia gRPC ‚Üí 15.7MB transferidos en 2.15s
‚úÖ Indexaci√≥n autom√°tica ‚Üí Archivo catalogado localmente
‚úÖ Disponibilidad confirmada ‚Üí B√∫squeda posterior encuentra archivo en C
```

---

## üé¨ CASOS DE DEMOSTRACI√ìN PARA VIDEO

### Caso 1: Flujo Completo P2P
**Duraci√≥n:** 3-4 minutos  
**Enfoque:** Demostrar flujo completo con logs detallados

### Caso 2: Concurrencia y Tolerancia a Fallos  
**Duraci√≥n:** 2-3 minutos  
**Enfoque:** Operaciones simult√°neas + simulaci√≥n de fallos

### Scripts de Demostraci√≥n
```bash
# Ejecutar casos de demostraci√≥n para video
python scripts/demo_cases.py

# Logs optimizados para captura de video
# Timestamps claros, mensajes descriptivos
# Evidencia visual del cumplimiento de criterios
```

---

## üöÄ DEPLOYMENT EN AWS

El sistema est√° preparado para deployment en m√°quinas virtuales AWS con:

- **Instancias EC2** configuradas autom√°ticamente
- **Security Groups** para tr√°fico REST y gRPC
- **Scripts de inicializaci√≥n** que instalan dependencias
- **Configuraci√≥n de red** para comunicaci√≥n entre VMs

**Resultado:** Sistema P2P completamente funcional y demostrable cumpliendo todos los criterios del proyecto.
